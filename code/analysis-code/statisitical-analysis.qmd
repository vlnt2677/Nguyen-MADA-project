---
title: "Analysis Script"
author: "Vincent Nguyen"
date: "2025-02-21"
output: html_document
---

# Setup

Load needed packages
```{r}
library(ggplot2) 
library(broom) 
library(here) 
library(glmnet)
library(MASS)
library(tidymodels)
library(dplyr)
library(rsample)
library(tibble)
library(parsnip)
library(future)
library(vip)
library(lubridate)
library(patchwork)
library(gtExtras)
library(webshot2)
library(gt)
```

Load in processed data and set eed
```{r}
# path to data
# note the use of the here() package and not absolute paths
data_location <- here::here("data","processed-data","processeddata.rds")

# load data 
data <- readRDS(data_location)

# set seed
rngseed = 1234
set.seed(rngseed)
```

Creation of lagged predictors
```{r}
# Creation of lagged cases and lagged mobility data
data <- data %>%
  group_by(county) %>%
  arrange(date) %>%
  mutate(
    lag_1 = lag(new_cases, 1),
    lag_7 = lag(new_cases, 7),
    lag_14 = lag(new_cases, 14),
    retail_lag7 = lag(retail_and_recreation_percent_change_from_baseline, 7),
    grocery_lag7 = lag(grocery_and_pharmacy_percent_change_from_baseline, 7),
    workplace_lag7 = lag(workplaces_percent_change_from_baseline, 7),
    residential_lag7 = lag(residential_percent_change_from_baseline, 7)
  ) %>%
  ungroup()

# remove NAs as result of lagging
data <- data %>% drop_na()
```

Implementation of rolling window cross-validation
```{r}
# Arrange by date
data <- data %>%
  arrange(date, county)

# Define testing set as last 30 days for 44 counties
test_days <- 30
last_date <- max(data$date)
test_start_date <- last_date - days(test_days - 1)

# Define train and test split through dates
train_data <- data %>% filter(date < test_start_date)
test_data  <- data %>% filter(date >= test_start_date)

# Create rolling window folds for cross-validation 
rolling_folds <- rolling_origin(
  data = train_data,
  initial = 120 * 44,  # ~4 months of training
  assess  = 30 * 44,   # ~1 month of validation
  skip    = 15 * 44,   # roll forward 15 days
  cumulative = FALSE
)

# Check date ranges for each fold
train_ranges <- purrr::map(rolling_folds$splits, ~range(pull(training(.x), date)))

# Print the ranges for each fold
train_ranges

# View fold summary
fold_sizes <- purrr::map_dfr(rolling_folds$splits, function(split) {
  tibble(
    train_n = nrow(training(split)),
    test_n  = nrow(testing(split))
  )
})

# Print
print(fold_sizes)

# Check date ranges
range(train_data$date)
range(test_data$date)
```

Recipe setting for modeling. Also rename the variable names.
```{r}
# Recipe for baseline model
recipe_baseline <- recipe(new_cases ~ pop_density + lag_1 + lag_7 + lag_14, data = data) %>% step_rename(
  Population_Density = pop_density,
    Lag_1_Day = lag_1,
    Lag_7_Days = lag_7,
    Lag_14_Days = lag_14
)

# Recipe with all predictors
recipe <- recipe(new_cases ~ pop_density +
                   retail_and_recreation_percent_change_from_baseline +
                   grocery_and_pharmacy_percent_change_from_baseline + 
                   workplaces_percent_change_from_baseline +
                   residential_percent_change_from_baseline +
                   lag_1 + lag_7 + lag_14, data = data) %>%
  step_rename(
    Population_Density = pop_density,
    Retail_Mobility = retail_and_recreation_percent_change_from_baseline,
    Grocery_Mobility = grocery_and_pharmacy_percent_change_from_baseline,
    Workplace_Mobility = workplaces_percent_change_from_baseline,
    Residential_Mobility = residential_percent_change_from_baseline,
    Lag_1_Day = lag_1,
    Lag_7_Days = lag_7,
    Lag_14_Days = lag_14
  )

# Recipe with lagged versions of mobility
recipe_lag <- recipe(new_cases ~ pop_density + retail_lag7 + grocery_lag7 + residential_lag7 + workplace_lag7 + lag_1 + lag_7 + lag_14, data = data) %>%
  step_rename(
    Population_Density = pop_density,
    Retail_Mobility_Lag7 = retail_lag7,
    Grocery_Mobility_Lag7 = grocery_lag7,
    Residential_Mobility_Lag7 = residential_lag7,
    Workplace_Mobility_Lag7 = workplace_lag7,
    Lag_1_Day = lag_1,
    Lag_7_Days = lag_7,
    Lag_14_Days = lag_14
  )
```

Modeling

The basic workflow is to fit a baseline model, fit the mobility model, and then fit the lagged model.

First model are linear regression models.
This code chunk fits a baseline linear regression model.
```{r}
# Define the Lasso model with tuning parameters
lasso_spec <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

# Create the Lasso workflow with baseline recipe
base_tuned_lasso_wf <- workflow() %>%
  add_recipe(recipe_baseline) %>%
  add_model(lasso_spec)

# Define a grid for tuning the penalty
lasso_grid <- grid_regular(penalty(range = c(-4, 0)), levels = 30)

# Tune the Lasso model using rolling origin cv
base_tuned_lasso_res <- tune_grid(
  base_tuned_lasso_wf,
  resamples = rolling_folds,
  grid = lasso_grid,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(parallel_over = "everything", save_pred = TRUE)
)

# View tuning results
autoplot(base_tuned_lasso_res)
base_tuned_lasso_metrics <- collect_metrics(base_tuned_lasso_res)
print(base_tuned_lasso_metrics)

# Select best penalty based on R-squared
base_tuned_lasso_best <- select_best(base_tuned_lasso_res, metric = "rsq")
print(base_tuned_lasso_best)

# Finalize the Lasso model with the selected penalty
base_final_lasso_spec <- linear_reg(
  penalty = base_tuned_lasso_best$penalty,
  mixture = 1
) %>%
  set_engine("glmnet")

# Final workflow with tuned Lasso model
base_final_lasso_wf <- workflow() %>%
  add_recipe(recipe_baseline) %>%
  add_model(base_final_lasso_spec)

# Fit the final Lasso model on training data
base_final_lasso_fit <- base_final_lasso_wf %>%
  fit(data = train_data)

# Evaluate the final Lasso model with rolling CV
base_final_lasso_res <- fit_resamples(
  base_final_lasso_wf,
  resamples = rolling_folds,
  metrics = metric_set(rmse, rsq, mae),
  control = control_resamples(save_pred = TRUE)
)

# View resampling performance for the final Lasso model
collect_metrics(base_final_lasso_res)

# Predict on test data using the final Lasso model
base_final_lasso_test_preds <- predict(base_final_lasso_fit, new_data = test_data)

# Combine predictions with actual values
base_final_lasso_test_results <- test_data %>%
  select(new_cases) %>%
  mutate(predicted = base_final_lasso_test_preds$.pred)

# Compute test metrics for the final Lasso model
base_final_lasso_test_metrics <- base_final_lasso_test_results %>%
  metrics(truth = new_cases, estimate = predicted)

# View the test set performance for the final Lasso model
print(base_final_lasso_test_metrics)
```

Collect Metrics and VIP
```{r}
# Collect CV metrics and drop extra columns
base_final_lasso_cv_metrics <- collect_metrics(base_final_lasso_res) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Train")

# Prepare Test metrics to match
base_final_lasso_test_metrics_fixed <- base_final_lasso_test_metrics %>%
  mutate(mean = .estimate) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Test")

# Combine CV and Test metrics
all_base_lasso_metrics <- bind_rows(
  base_final_lasso_cv_metrics,
  base_final_lasso_test_metrics_fixed
)

# View the final combined metrics
print(all_base_lasso_metrics)

# View variable importance for the Lasso model
vip_base_lasso <- vip(base_final_lasso_fit$fit$fit)

# Alter aesthetics
vip_base_lasso <- vip_base_lasso + labs(
  title = "Baseline LASSO Variable Importance",
  x = "Importance",
  y = "Feature"
) + theme_bw()

figure_file = here("results", "figures", "vip_base_lasso.png")
ggsave(filename = figure_file, plot = vip_base_lasso, width = 8, height = 6, dpi = 300)
```

This code chunk fits a linear regression model with mobility predictors.
```{r}
# Create the Lasso workflow
lasso_wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(lasso_spec)

# Tune the Lasso model using time-blocked CV
lasso_res <- tune_grid(
  lasso_wf,
  resamples = rolling_folds,
  grid = lasso_grid,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(save_pred = TRUE)
)

# View tuning results
autoplot(lasso_res)
lasso_metrics <- collect_metrics(lasso_res)
print(lasso_metrics)

# Select best penalty by R-squared
lasso_best <- select_best(lasso_res, metric = "rsq")
print(lasso_best)

# Finalize the Lasso model with selected lambda
final_lasso_spec <- linear_reg(
  penalty = lasso_best$penalty,
  mixture = 1
) %>%
  set_engine("glmnet")

# Final workflow with tuned Lasso model
final_lasso_wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(final_lasso_spec)

# Fit final model on training data
final_lasso_fit <- final_lasso_wf %>%
  fit(data = train_data)

# Evaluate final model with rolling CV
final_lasso_res <- fit_resamples(
  final_lasso_wf,
  resamples = rolling_folds,
  metrics = metric_set(rmse, rsq, mae),
  control = control_resamples(save_pred = TRUE)
)

# View resampling performance
collect_metrics(final_lasso_res)

# Predict on test data
final_lasso_test_preds <- predict(final_lasso_fit, new_data = test_data)

# Combine predictions with actuals
final_lasso_test_results <- test_data %>%
  select(new_cases) %>%
  mutate(predicted = final_lasso_test_preds$.pred)

# Compute test metrics
final_lasso_test_metrics <- final_lasso_test_results %>%
  metrics(truth = new_cases, estimate = predicted)

# View test set performance
print(final_lasso_test_metrics)
```

Collect Metrics and VIP
```{r}
# Collect CV metrics and drop extra columns
final_lasso_cv_metrics <- collect_metrics(final_lasso_res) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Train")

# Prepare Test metrics to match
final_lasso_test_metrics_fixed <- final_lasso_test_metrics %>%
  mutate(mean = .estimate) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Test")

# Combine CV and Test metrics
all_lasso_metrics <- bind_rows(
  final_lasso_cv_metrics,
  final_lasso_test_metrics_fixed
)

# View the final combined metrics
print(all_lasso_metrics)

# Plot VIP
vip_full_lasso <- vip(final_lasso_fit$fit$fit)

# Alter aesthetics
vip_full_lasso <- vip_full_lasso + 
  labs(
    title = "LASSO with Mobility Variable Importance",
    x = "Importance",
    y = "Feature"
  ) + 
  theme_bw()

# Define save location
figure_file <- here("results", "figures", "vip_full_lasso.png")

# Save plot
ggsave(filename = figure_file, plot = vip_full_lasso, width = 8, height = 6, dpi = 300)
```

```{r}
# Create the Lasso workflow
lag_lasso_wf <- workflow() %>%
  add_recipe(recipe_lag) %>%
  add_model(lasso_spec)

# Tune the Lasso model using time-blocked CV
lag_lasso_res <- tune_grid(
  lag_lasso_wf,
  resamples = rolling_folds,
  grid = lasso_grid,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(save_pred = TRUE)
)

# View tuning results
autoplot(lag_lasso_res)
lag_lasso_metrics <- collect_metrics(lag_lasso_res)
print(lag_lasso_metrics)

# Select best penalty by R-squared
lag_lasso_best <- select_best(lag_lasso_res, metric = "rsq")
print(lag_lasso_best)

# Finalize the Lasso model with selected lambda
lag_final_lasso_spec <- linear_reg(
  penalty = lag_lasso_best$penalty,
  mixture = 1
) %>%
  set_engine("glmnet")

# Final workflow with tuned Lasso model
lag_final_lasso_wf <- workflow() %>%
  add_recipe(recipe_lag) %>%
  add_model(lag_final_lasso_spec)

# Fit final model on training data
lag_final_lasso_fit <- lag_final_lasso_wf %>%
  fit(data = train_data)

# Evaluate final model with rolling CV
lag_final_lasso_res <- fit_resamples(
  lag_final_lasso_wf,
  resamples = rolling_folds,
  metrics = metric_set(rmse, rsq, mae),
  control = control_resamples(save_pred = TRUE)
)

# View resampling performance
collect_metrics(lag_final_lasso_res)

# Predict on test data
lag_final_lasso_test_preds <- predict(lag_final_lasso_fit, new_data = test_data)

# Combine predictions with actuals
lag_final_lasso_test_results <- test_data %>%
  select(new_cases) %>%
  mutate(predicted = lag_final_lasso_test_preds$.pred)

# Compute test metrics
lag_final_lasso_test_metrics <- lag_final_lasso_test_results %>%
  metrics(truth = new_cases, estimate = predicted)

# View test set performance
print(lag_final_lasso_test_metrics)
```

Collect Metrics and VIP
```{r}
# Collect CV metrics and drop extra columns
lag_final_lasso_cv_metrics <- collect_metrics(lag_final_lasso_res) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Train")

# Prepare Test metrics to match
lag_final_lasso_test_metrics_fixed <- lag_final_lasso_test_metrics %>%
  mutate(mean = .estimate) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Test")

# Combine CV and Test metrics
all_lag_lasso_metrics <- bind_rows(
  lag_final_lasso_cv_metrics,
  lag_final_lasso_test_metrics_fixed
)

# View the final combined metrics
print(all_lag_lasso_metrics)

# Plot VIP
vip_lag_lasso <- vip(lag_final_lasso_fit$fit$fit)

# Alter aesthetics
vip_lag_lasso <- vip_lag_lasso + 
  labs(
    title = "LASSO with Lagged Mobility Variable Importance",
    x = "Importance",
    y = "Feature"
  ) + 
  theme_bw()

# Define save location
figure_file <- here("results", "figures", "vip_lag_lasso.png")

# Save plot
ggsave(filename = figure_file, plot = vip_lag_lasso, width = 8, height = 6, dpi = 300)

```

```{r}
# plot baseline lasso model prediction vs actual
plot_base_lasso <- base_final_lasso_test_results %>%
  ggplot(aes(x = new_cases, y = predicted)) +
  geom_point(alpha = 0.6, color = "#69b3a2") +
  geom_abline(slope = 1, intercept = 0, color = "#DBA2A2", linetype = "dashed") +
  labs(
    title = "Base Lasso",
    x = "Actual Cases", y = "Predicted Cases"
  ) +
  theme_bw()

# plot mobility lasso model prediction vs actual
plot_lasso <- final_lasso_test_results %>%
  ggplot(aes(x = new_cases, y = predicted)) +
  geom_point(alpha = 0.6, color = "#BFA2DB") +
  geom_abline(slope = 1, intercept = 0, color = "#DBA2A2", linetype = "dashed") +
  labs(
    title = "Lasso",
    x = "Actual Cases", y = "Predicted Cases"
  ) +
  theme_bw()

# plot lagged lasso model prediction vs actual
plot_lag_lasso <- lag_final_lasso_test_results %>%
  ggplot(aes(x = new_cases, y = predicted)) +
  geom_point(alpha = 0.6, color = "#F2C29B") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "#DBA2A2") +
  labs(
    title = "Lag Lasso",
    x = "Actual Cases", y = "Predicted Cases"
  ) +
  theme_bw()

# Combine + formatting
lasso_graphs <- plot_base_lasso + plot_lasso + plot_lag_lasso +
  plot_layout(ncol = 3, widths = c(1.5, 1.5, 1.5)) &
  theme(
    plot.margin = margin(10, 10, 10, 10),
    plot.title = element_text(size = 20, hjust = 0.5),
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 16)
  )


# Print graph for inspection
print(lasso_graphs)

# Save file
figure_file = here("results", "figures", "lasso_graphs.png")
ggsave(
  filename = figure_file,
  plot = lasso_graphs,
  width = 18, height = 6, dpi = 400
)
```


Second, random forest models are tuned, trained, and evaluated. Best models are chosen through R-squared.

This code chunk fits and tunes a baseline RF model with no mobility predictors.
```{r}
# Define the Random Forest model with tuning parameters
forest_spec <- rand_forest(
  mode = "regression", 
  mtry = tune(),           
  min_n = tune(),          
  trees = 500              
) %>%
  set_engine("ranger", seed = rngseed)

# Create grid of hyperparameters for tuning
forest_grid <- grid_regular(
  mtry(range = c(1, 4)),  
  min_n(range = c(1, 50)), 
  levels = 10
)

# Create baseline workflow with baseline recipe
base_tuned_rf_wf <- workflow() %>%
  add_recipe(recipe_baseline) %>%
  add_model(forest_spec)

# Tune the Random Forest model using time-blocked CV (folds)
base_tuned_rf_res <- tune_grid(
  base_tuned_rf_wf,
  resamples = rolling_folds,                     
  grid = forest_grid,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(parallel_over = "everything")
)

# View tuning results
autoplot(base_tuned_rf_res)
base_tune_rf_metrics <- collect_metrics(base_tuned_rf_res)
print(base_tune_rf_metrics)

# Select best hyperparameters by R-squared
base_tuned_rf_best <- select_best(base_tuned_rf_res, metric = "rsq")

# Finalize model with best parameters
base_final_rf_spec <- rand_forest(
  mode = "regression",
  mtry = base_tuned_rf_best$mtry,
  min_n = base_tuned_rf_best$min_n,
  trees = 500
) %>%
  set_engine("ranger", seed = rngseed, importance = "impurity")

# Final workflow with tuned model
base_final_rf_wf <- workflow() %>%
  add_recipe(recipe_baseline) %>%
  add_model(base_final_rf_spec)

# Fit final model on training data
base_final_rf_fit <- base_final_rf_wf %>%
  fit(data = train_data)

# Evaluate final model with rolling CV
base_final_rf_res <- fit_resamples(
  base_final_rf_wf,
  resamples = rolling_folds,
  metrics = metric_set(rmse, rsq, mae),
  control = control_resamples(save_pred = TRUE)
)

# View resampling performance
collect_metrics(base_final_rf_res)

# Predict on test data
base_final_rf_test_preds <- predict(base_final_rf_fit, new_data = test_data)

# Combine predictions with actuals
base_final_rf_test_results <- test_data %>%
  select(new_cases) %>%
  mutate(predicted = base_final_rf_test_preds$.pred)

# Compute test metrics
base_final_rf_test_metrics <- base_final_rf_test_results %>%
  metrics(truth = new_cases, estimate = predicted)

# View test set performance
print(base_final_rf_test_metrics)
```

Collect metrics and VIP
```{r}
# Collect CV metrics and drop extra columns
base_final_rf_cv_metrics <- collect_metrics(base_final_rf_res) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Train")

# Prepare test metrics to match format
base_final_rf_test_metrics_fixed <- base_final_rf_test_metrics %>%
  mutate(mean = .estimate) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Test")

# Combine CV and Test metrics
all_base_rf_metrics <- bind_rows(
  base_final_rf_cv_metrics,
  base_final_rf_test_metrics_fixed
)

# Print metrics
print(all_base_rf_metrics)

# Create vip
vip_base_rf <- vip(base_final_rf_fit)

# Alter aesthetics
vip_base_rf <- vip_base_rf + 
  labs(
    title = "Baseline Random Forest Variable Importance",
    x = "Importance",
    y = "Feature"
  ) + 
  theme_bw()

# Save vip
figure_file <- here("results", "figures", "vip_base_rf.png")
ggsave(filename = figure_file, plot = vip_base_rf, width = 8, height = 6, dpi = 300)
```

This code chunk fits and tunes a RF model with mobility predictors.
```{r}
# Create workflow with baseline recipe
tuned_rf_wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(forest_spec)

# Tune the Random Forest model using time-blocked CV (folds)
rf_tune_res <- tune_grid(
  tuned_rf_wf,
  resamples = rolling_folds,                     
  grid = forest_grid,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(parallel_over = "everything")
)

# View tuning results
autoplot(rf_tune_res)
rf_tune_metrics <- collect_metrics(rf_tune_res)
print(rf_tune_metrics)

# Select best hyperparameters by R-squared
rf_best <- select_best(rf_tune_res, metric = "rsq")

# Finalize model with best parameters
final_rf_spec <- rand_forest(
  mode = "regression",
  mtry = rf_best$mtry,
  min_n = rf_best$min_n,
  trees = 500
) %>%
  set_engine("ranger", seed = rngseed, importance = "impurity")

# Final workflow with tuned model
final_rf_wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(final_rf_spec)

# Fit final model on training data
final_rf_fit <- final_rf_wf %>%
  fit(data = train_data)

# Evaluate final model with rolling CV
final_rf_res <- fit_resamples(
  final_rf_wf,
  resamples = rolling_folds,
  metrics = metric_set(rmse, rsq, mae),
  control = control_resamples(save_pred = TRUE)
)

# View resampling performance
collect_metrics(final_rf_res)

# Predict on test data
final_rf_test_preds <- predict(final_rf_fit, new_data = test_data)

# Combine predictions with actuals
final_rf_test_results <- test_data %>%
  select(new_cases) %>%
  mutate(predicted = final_rf_test_preds$.pred)

# Compute test metrics
final_rf_test_metrics <- final_rf_test_results %>%
  metrics(truth = new_cases, estimate = predicted)

# View test set performance
print(final_rf_test_metrics)
```

Collect metrics and VIP
```{r}
# Collect CV metrics and drop extra columns
final_rf_cv_metrics <- collect_metrics(final_rf_res) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Train")

# Prepare test metrics to match format
final_rf_test_metrics_fixed <- final_rf_test_metrics %>%
  mutate(mean = .estimate) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Test")

# Combine CV and Test metrics
all_rf_metrics <- bind_rows(
  final_rf_cv_metrics,
  final_rf_test_metrics_fixed
)

# Print metrics
print(all_rf_metrics)

# Create vip
vip_full_rf <- vip(final_rf_fit)

# Alter aesthetics
vip_full_rf <- vip_full_rf + 
  labs(
    title = "Random Forest with Mobility Variable Importance",
    x = "Importance",
    y = "Feature"
  ) + 
  theme_bw()

# Save vip
figure_file <- here("results", "figures", "vip_full_rf.png")
ggsave(filename = figure_file, plot = vip_full_rf, width = 8, height = 6, dpi = 300)
```

This code chunk fits and tunes a RF model with lagged mobility predictors.
```{r}
# Create lag workflow with baseline recipe
lag_tuned_rf_wf <- workflow() %>%
  add_recipe(recipe_lag) %>%
  add_model(forest_spec)

# Tune the Random Forest model using time-blocked CV (folds)
lag_tuned_rf_res <- tune_grid(
  lag_tuned_rf_wf,
  resamples = rolling_folds,                     
  grid = forest_grid,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(parallel_over = "everything")
)

# View tuning results
autoplot(lag_tuned_rf_res)
lag_tune_rf_metrics <- collect_metrics(lag_tuned_rf_res)
print(lag_tune_rf_metrics)

# Select best hyperparameters by R-squared
lag_tuned_rf_best <- select_best(lag_tuned_rf_res, metric = "rsq")

# Finalize model with best parameters
lag_final_rf_spec <- rand_forest(
  mode = "regression",
  mtry = lag_tuned_rf_best$mtry,
  min_n = lag_tuned_rf_best$min_n,
  trees = 500
) %>%
  set_engine("ranger", seed = rngseed, importance = "impurity")

# Final workflow with tuned model
lag_final_rf_wf <- workflow() %>%
  add_recipe(recipe_lag) %>%
  add_model(lag_final_rf_spec)

# Fit final model on training data
lag_final_rf_fit <- lag_final_rf_wf %>%
  fit(data = train_data)

# Evaluate final model with rolling CV
lag_final_rf_res <- fit_resamples(
  lag_final_rf_wf,
  resamples = rolling_folds,
  metrics = metric_set(rmse, rsq, mae),
  control = control_resamples(save_pred = TRUE)
)

# View resampling performance
collect_metrics(lag_final_rf_res)

# Predict on test data
lag_final_rf_test_preds <- predict(lag_final_rf_fit, new_data = test_data)

# Combine predictions with actuals
lag_final_rf_test_results <- test_data %>%
  select(new_cases) %>%
  mutate(predicted = lag_final_rf_test_preds$.pred)

# Compute test metrics
lag_final_rf_test_metrics <- lag_final_rf_test_results %>%
  metrics(truth = new_cases, estimate = predicted)

# View test set performance
print(lag_final_rf_test_metrics)
```

Collect metrics and CV
```{r}
# Collect CV metrics and drop extra columns
lag_final_rf_cv_metrics <- collect_metrics(lag_final_rf_res) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Train")

# Prepare test metrics to match format
lag_final_rf_test_metrics_fixed <- lag_final_rf_test_metrics %>%
  mutate(mean = .estimate) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Test")

# Combine CV and Test metrics
all_lag_rf_metrics <- bind_rows(
  lag_final_rf_cv_metrics,
  lag_final_rf_test_metrics_fixed
)

# Print metrics
print(all_lag_rf_metrics)

# Create vip
vip_lag_rf <- vip(lag_final_rf_fit)

# Alter aesthetics
vip_lag_rf <- vip_lag_rf + 
  labs(
    title = "Random Forest with Lagged Mobility Variable Importance",
    x = "Importance",
    y = "Feature"
  ) + 
  theme_bw()

# Save vip
figure_file <- here("results", "figures", "vip_lag_rf.png")
ggsave(filename = figure_file, plot = vip_lag_rf, width = 8, height = 6, dpi = 300)
```

```{r}
# plot baseline rf model prediction vs actual
plot_base_rf <- base_final_rf_test_results %>%
  ggplot(aes(x = new_cases, y = predicted)) +
  geom_point(alpha = 0.6, color = "#69b3a2") +
  geom_abline(slope = 1, intercept = 0, color = "#DBA2A2", linetype = "dashed") +
  labs(
    title = "Base RF",
    x = "Actual Cases", y = "Predicted Cases"
  ) +
  theme_bw()

# plot mobility rf model prediction vs actual
plot_rf <- final_rf_test_results %>%
  ggplot(aes(x = new_cases, y = predicted)) +
  geom_point(alpha = 0.6, color = "#BFA2DB") +
  geom_abline(slope = 1, intercept = 0, color = "#DBA2A2", linetype = "dashed") +
  labs(
    title = "RF with Mobility",
    x = "Actual Cases", y = "Predicted Cases"
  ) +
  theme_bw()

# plot lagged rf model prediction vs actual
plot_lag_rf <- lag_final_rf_test_results %>%
  ggplot(aes(x = new_cases, y = predicted)) +
  geom_point(alpha = 0.6, color = "#F2C29B") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "#DBA2A2") +
  labs(
    title = "RF with Lagged Mobility",
    x = "Actual Cases", y = "Predicted Cases"
  ) +
  theme_bw()

# Combine + formatting
rf_graphs <- plot_base_rf + plot_rf + plot_lag_rf +
  plot_layout(ncol = 3, widths = c(1.5, 1.5, 1.5)) &
  theme(
    plot.margin = margin(10, 10, 10, 10),
    plot.title = element_text(size = 20, hjust = 0.5),
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 16)
  )

# Print for visual inspection
print(rf_graphs)

# Save file
figure_file = here("results", "figures", "rf_graphs.png")
ggsave(
  filename = figure_file,
  plot = rf_graphs,
  width = 18, height = 6, dpi = 400
)
```

Third, XGBoost models are tuned, trained, and evaluated. Best models are chosen through R-squared.

This code chunk fits and tunes an baseline XGBoost model with no mobility predictors.
```{r}
# Define the XGBoost model specification (baseline version)
boost_spec <- boost_tree(
  trees = 500,
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune()
) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

# Build workflow with baseline recipe and model
base_boost_wf <- workflow() %>%
  add_recipe(recipe_baseline) %>%
  add_model(boost_spec)

# Tune XGBoost model using time-blocked CV (folds)
base_boost_tune_res <- tune_grid(
  base_boost_wf,
  resamples = rolling_folds,
  grid = 30,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(parallel_over = "everything")
)

# View tuning results and print best model metrics
base_boost_tune_res %>%
  collect_metrics() %>%
  print()

autoplot(base_boost_tune_res)

base_best_params <- select_best(base_boost_tune_res, metric = "rsq")
print(base_best_params)

# Final XGBoost model with best hyperparameters
base_final_boost_spec <- boost_tree(
  trees = 500,
  tree_depth = base_best_params$tree_depth,
  learn_rate = base_best_params$learn_rate,
  loss_reduction = base_best_params$loss_reduction
) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

# Final model workflow
base_final_boost_wf <- workflow() %>%
  add_recipe(recipe_baseline) %>%
  add_model(base_final_boost_spec)

# Fit the final model
base_final_boost_fit <- base_final_boost_wf %>%
  fit(data = train_data)

# Predict on test data and compute performance metrics
base_final_boost_preds <- predict(base_final_boost_fit, new_data = test_data)

# Create tibble with truth and predcitions
base_final_boost_results <- tibble(
  truth = test_data$new_cases,
  predicted = base_final_boost_preds$.pred
)

# Calculate metrics using previous tibble
base_final_boost_metrics <- base_final_boost_results %>%
  metrics(truth = truth, estimate = predicted)

# Print final performance metrics
print(base_final_boost_metrics)

# Extract Model
base_boost_model <- base_final_boost_fit$fit$fit
```

Collect metrics and VIP
```{r}

# select metrics from best model
base_boost_cv_metrics <- base_boost_tune_res %>%
  collect_metrics() %>%
  inner_join(base_best_params, by = c("tree_depth", "learn_rate", "loss_reduction")) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Train")

# Prepare test metrics to match format
base_final_boost_test_metrics <- base_final_boost_results %>%
  metrics(truth = truth, estimate = predicted) %>%
  mutate(mean = .estimate) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Test")

# Combine CV and Test metrics
all_base_boost_metrics <- bind_rows(
  base_boost_cv_metrics,
  base_final_boost_test_metrics
)

# Print metrics
print(all_base_boost_metrics)

# Create vip
vip_base_boost <- vip(base_boost_model)

# Alter aesthetics
vip_base_boost <- vip_base_boost + 
  labs(
    title = "Baseline XGBoost Variable Importance",
    x = "Importance",
    y = "Feature"
  ) + 
  theme_bw()

# Print
print(vip_base_boost)

# Save vip
figure_file <- here("results", "figures", "vip_base_boost.png")
ggsave(filename = figure_file, plot = vip_base_boost, width = 8, height = 6, dpi = 300)
```

This code chunk fits and tunes an XGBoost model with mobility predictors.
```{r}
# Build workflow with recipe and model
boost_wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(boost_spec)

# Tune XGBoost model using time-blocked CV (folds)
boost_tune_res <- tune_grid(
  boost_wf,
  resamples = rolling_folds,
  grid = 30,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(parallel_over = "everything")
)

# View tuning results and print best model metrics
boost_tune_res %>%
  collect_metrics() %>%
  print()
autoplot(boost_tune_res)


best_params <- select_best(boost_tune_res, metric = "rsq")
print(best_params)

# Final XGBoost model with best hyperparameters
final_boost_spec <- boost_tree(
  trees = 500,
  tree_depth = best_params$tree_depth,
  learn_rate = best_params$learn_rate,
  loss_reduction = best_params$loss_reduction
) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

# Final model workflow
final_boost_wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(final_boost_spec)

# Fit the final model
final_boost_fit <- final_boost_wf %>%
  fit(data = train_data)

# Predict on test data and compute performance metrics
final_boost_preds <- predict(final_boost_fit, new_data = test_data)

# Create tibble with truth and predcitions
final_boost_results <- tibble(
  truth = test_data$new_cases,
  predicted = final_boost_preds$.pred
)

# Calculate metrics using previous tibble
final_boost_metrics <- final_boost_results %>%
  metrics(truth = truth, estimate = predicted)

# Print final performance metrics
print(final_boost_metrics)

# Extract Model
full_boost_model <- final_boost_fit$fit$fit
```

Collect metrics and VIP
```{r}
# Collect CV metrics and drop extra columns
boost_cv_metrics <- boost_tune_res %>%
  collect_metrics() %>%
  inner_join(best_params, by = c("tree_depth", "learn_rate", "loss_reduction")) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Train")

# Prepare test metrics to match format
final_boost_test_metrics <- final_boost_results %>%
  metrics(truth = truth, estimate = predicted) %>%
  mutate(mean = .estimate) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Test")

# Combine CV and Test metrics
all_boost_metrics <- bind_rows(
  boost_cv_metrics,
  final_boost_test_metrics
)

# Print metrics
print(all_boost_metrics)

# Create vip
vip_full_boost <- vip(full_boost_model)

# Alter aesthetics
vip_full_boost <- vip_full_boost + 
  labs(
    title = "XGBoost with Mobility Variable Importance",
    x = "Importance",
    y = "Feature"
  ) + 
  theme_bw()

# Save vip
figure_file <- here("results", "figures", "vip_full_boost.png")
ggsave(filename = figure_file, plot = vip_full_boost, width = 8, height = 6, dpi = 300)
```

This code chunk fits and tunes an XGBoost model with lagged mobility predictors.
```{r}
# Build workflow with baseline recipe and model
lag_boost_wf <- workflow() %>%
  add_recipe(recipe_lag) %>%
  add_model(boost_spec)

# Tune XGBoost model using time-blocked CV (folds)
lag_boost_tune_res <- tune_grid(
  lag_boost_wf,
  resamples = rolling_folds,
  grid = 30,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(parallel_over = "everything")
)

# View tuning results and print best model metrics
lag_boost_tune_res %>%
  collect_metrics() %>%
  print()

lag_best_params <- select_best(lag_boost_tune_res, metric = "rsq")
print(lag_best_params)

# Final XGBoost model with best hyperparameters
lag_final_boost_spec <- boost_tree(
  trees = 500,
  tree_depth = lag_best_params$tree_depth,
  learn_rate = lag_best_params$learn_rate,
  loss_reduction = lag_best_params$loss_reduction
) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

# Final model workflow
lag_final_boost_wf <- workflow() %>%
  add_recipe(recipe_lag) %>%
  add_model(lag_final_boost_spec)

# Fit the final model
lag_final_boost_fit <- lag_final_boost_wf %>%
  fit(data = train_data)

# Predict on test data and compute performance metrics
lag_final_boost_preds <- predict(lag_final_boost_fit, new_data = test_data)

# Create tibble with truth and predcitions
lag_final_boost_results <- tibble(
  truth = test_data$new_cases,
  predicted = lag_final_boost_preds$.pred
)

# Calculate metrics using previous tibble
lag_final_boost_metrics <- lag_final_boost_results %>%
  metrics(truth = truth, estimate = predicted)

# Print final performance metrics
print(lag_final_boost_metrics)

# Extract Model
lag_boost_model <- lag_final_boost_fit$fit$fit
```

Collect metrics and VIP
```{r}
# Collect CV metrics and drop extra columns
lag_boost_cv_metrics <- lag_boost_tune_res %>%
  collect_metrics() %>%
  inner_join(lag_best_params, by = c("tree_depth", "learn_rate", "loss_reduction")) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Train")

# Prepare test metrics to match format
lag_final_boost_test_metrics <- lag_final_boost_results %>%
  metrics(truth = truth, estimate = predicted) %>%
  mutate(mean = .estimate) %>%
  select(.metric, .estimator, mean) %>%
  mutate(Data = "Test")

# Combine CV and Test metrics
all_lag_boost_metrics <- bind_rows(
  lag_boost_cv_metrics,
  lag_final_boost_test_metrics
)

# Print metrics
print(all_lag_boost_metrics)

# Create vip
vip_lag_boost <- vip(lag_boost_model)

# Alter aesthetics
vip_lag_boost <- vip_lag_boost + 
  labs(
    title = "XGBoost with Lagged Mobility Variable Importance",
    x = "Importance",
    y = "Feature"
  ) + 
  theme_bw()

# Print
print(vip_lag_boost)

# Save vip
figure_file <- here("results", "figures", "vip_lag_boost.png")
ggsave(filename = figure_file, plot = vip_lag_boost, width = 8, height = 6, dpi = 300)
```

```{r}
# plot baseline boost model prediction vs. actual
plot_base_boost <- base_final_boost_results %>%
  ggplot(aes(x = truth, y = predicted)) +
  geom_point(alpha = 0.6, color = "#69b3a2") +
  geom_abline(slope = 1, intercept = 0, color = "#DBA2A2", linetype = "dashed") +
  labs(
    title = "Base Boost",
    x = "Actual Cases", y = "Predicted Cases"
  ) +
  theme_bw()

# plot mobility boost model prediction vs actual
plot_boost <- final_boost_results %>%
  ggplot(aes(x = truth, y = predicted)) +
  geom_point(alpha = 0.6, color = "#BFA2DB") +
  geom_abline(slope = 1, intercept = 0, color = "#DBA2A2", linetype = "dashed") +
  labs(
    title = "Boost with Mobility",
    x = "Actual Cases", y = "Predicted Cases"
  ) +
  theme_bw()

# plot lagged boost model prediction vs actual
plot_lag_boost <- lag_final_boost_results %>%
  ggplot(aes(x = truth, y = predicted)) +
  geom_point(alpha = 0.6, color = "#F2C29B") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "#DBA2A2") +
  labs(
    title = "Boost with Lagged Mobility",
    x = "Actual Cases", y = "Predicted Cases"
  ) +
  theme_bw()

# Combine graphs + formatting
boost_graphs <- plot_base_boost + plot_boost + plot_lag_boost +
  plot_layout(ncol = 3, widths = c(1.5, 1.5, 1.5)) &
  theme(
    plot.margin = margin(10, 10, 10, 10),
    plot.title = element_text(size = 20, hjust = 0.5),
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 16)
  )

# Print for visual inspection
print(boost_graphs)

# Save file
figure_file = here("results", "figures", "boost_graphs.png")
ggsave(
  filename = figure_file,
  plot = boost_graphs,
  width = 18, height = 6, dpi = 400
)

```

This code chunk merges the results of the best models into a data frame.
```{r}
# Reformat these data frames for joining
base_lasso_metrics <- all_base_lasso_metrics %>% 
  mutate(model = "LASSO (Baseline)")

lasso_metrics <- all_lasso_metrics %>% 
  mutate(model = "LASSO")

lag_lasso_metrics <- all_lag_lasso_metrics %>% 
  mutate(model = "LASSO (Lagged Mobility)")

base_final_boost_metrics <- all_base_boost_metrics %>%
  mutate(model = "XGBoost (Baseline)")

final_boost_metrics <- all_boost_metrics %>%
  mutate(model = "XGBoost")

lag_boost_metrics <- all_lag_boost_metrics %>%
  mutate(model = "XGBoost (Lagged Mobility)")

base_final_forest_metrics <- all_base_rf_metrics %>%
  mutate(model = "Random Forest (Baseline)")

final_forest_metrics <- all_rf_metrics %>%
  mutate(model = "Random Forest")

lag_forest_metrics <- all_lag_rf_metrics %>%
  mutate(model = "Random Forest (Lagged Mobility)")

# Join all metrics together
model_metrics <- bind_rows(base_lasso_metrics, lasso_metrics, lag_lasso_metrics, base_final_boost_metrics, final_boost_metrics, lag_boost_metrics, base_final_forest_metrics, final_forest_metrics, lag_forest_metrics)

# Pivot and remove unncessary columns
model_metrics <- model_metrics %>%
  select(-.estimator) %>%
  pivot_wider(names_from = c('.metric', 'Data'), values_from = mean)
```

This code chunk creates a short summary table of the results from the model_metrics data frame.

```{r}
# Create table and also reorder data frame columns
model_table <- model_metrics %>%
  select(model, rmse_Train, mae_Train, rsq_Train, rmse_Test, mae_Test, rsq_Test) %>%
  gt() %>%
  tab_header(
    title = "Model Performance Metrics",
    subtitle = "Train and Test Results | Best Performance Highlighted in Green"
  ) %>%
  fmt_number(columns = everything(), decimals = 3) %>%
  cols_label(
    model = "Model",
    rmse_Train = "RMSE",
    mae_Train = "MAE",
    rsq_Train = "R²",
    rmse_Test = "RMSE",
    mae_Test = "MAE",
    rsq_Test = "R²"
  ) %>%
  tab_spanner(
    label = "Train Metrics",
    columns = c(rmse_Train, mae_Train, rsq_Train)
  ) %>%
  tab_spanner(
    label = "Test Metrics",
    columns = c(rmse_Test, mae_Test, rsq_Test)
  ) %>%
  tab_style(
    style = cell_fill(color = "lightgreen"),
    locations = cells_body(
      columns = rmse_Test,
      rows = rmse_Test == min(rmse_Test, na.rm = TRUE)
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "lightgreen"),
    locations = cells_body(
      columns = mae_Test,
      rows = mae_Test == min(mae_Test, na.rm = TRUE)
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "lightgreen"),
    locations = cells_body(
      columns = rsq_Test,
      rows = rsq_Test == max(rsq_Test, na.rm = TRUE)
    )
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  ) %>%
  tab_options(
    table.width = pct(100),
    table.align = "left",
    column_labels.padding = px(10),
    data_row.padding = px(6)
  )

print(model_table)

gtsave(model_table, here("results", "figures", "models.png"))
```